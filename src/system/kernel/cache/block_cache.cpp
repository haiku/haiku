/*
 * Copyright 2004-2023, Axel DÃ¶rfler, axeld@pinc-software.de.
 * Copyright 2023, Your Name, your.email@example.com.
 * Distributed under the terms of the MIT License.
 */

#include "block_cache_private.h" // Includes Slab.h, fs_cache.h etc.

#include <unistd.h>
#include <stdlib.h>
#include <string.h>
#include <errno.h>
#include <sys/uio.h> // For struct iovec

#include <KernelExport.h>

#include <condition_variable.h>
#include <lock.h>
#include <low_resource_manager.h>
// #include <slab/Slab.h> // Included via block_cache_private.h
// #include <tracing.h> // For T, TB, etc. if defined there
#include <util/kernel_cpp.h>
#include <util/DoublyLinkedList.h>
#include <util/AutoLock.h>
#include <StackOrHeapArray.h>
#include <vm/vm_page.h>

#ifndef BUILDING_USERLAND_FS_SERVER
// #include "IORequest.h"
#endif

#ifdef _KERNEL_MODE
#	define TRACE_ALWAYS(x...) dprintf(x)
#else
#	define TRACE_ALWAYS(x...) printf(x)
#endif

//#define TRACE_BLOCK_CACHE
#ifdef TRACE_BLOCK_CACHE
#	define TRACE(x)	TRACE_ALWAYS(x)
#else
#	define TRACE(x) ;
#endif

#define FATAL(x) panic x

// Tracing macros - define them as no-ops for now
#define T(x) ((void)0)
#define TB(x) ((void)0)
#define TB2(x) ((void)0)

static const bigtime_t kTransactionIdleTime = 2000000LL;

DoublyLinkedList<block_cache> sCaches;
mutex sCachesLock = MUTEX_INITIALIZER("block_caches_list_lock");
mutex sNotificationsLock = MUTEX_INITIALIZER("block_cache_notifications_lock");
mutex sCachesMemoryUseLock = MUTEX_INITIALIZER("block_cache_memory_use_lock");

object_cache* sBlockCache = NULL;
object_cache* sCacheNotificationCache = NULL;
object_cache* sTransactionObjectCache = NULL;

sem_id sEventSemaphore = -1;
thread_id sNotifierWriterThread = -1;

// Definition for sMarkCache needs to be after block_cache is fully defined.
// block_cache sMarkCache(0,0,0,false); // Placeholder, might need specific dummy values
size_t sUsedMemory = 0;


namespace { // Anonymous namespace

// cache_notification and cache_listener full definitions are now in block_cache_private.h

void*
cache_notification::operator new(size_t size)
{
	if (sCacheNotificationCache == NULL) {
		panic("cache_notification::new: sCacheNotificationCache is NULL!");
	}
	void* block = object_cache_alloc(sCacheNotificationCache, 0);
	if (block == NULL) {
		panic("cache_notification::new: object_cache_alloc failed!");
	}
	return block;
}

void
cache_notification::operator delete(void* block)
{
	if (sCacheNotificationCache == NULL) {
		panic("cache_notification::delete: sCacheNotificationCache is NULL!");
		return;
	}
	if (block != NULL)
		object_cache_free(sCacheNotificationCache, block, 0);
}


class BlockWriter {
public:
	BlockWriter(block_cache* cache, size_t max = SIZE_MAX);
	~BlockWriter();

	bool Add(cached_block* block, cache_transaction* transaction = NULL);
	bool Add(cache_transaction* transaction, bool& hasLeftOvers);
	status_t Write(cache_transaction* transaction = NULL, bool canUnlock = true);
	status_t WriteBlock(cached_block* block);
	bool DeletedTransaction() const { return fDeletedTransaction; }

private:
	void* _Data(cached_block* block) const;
	status_t _WriteBlocks(cached_block** blocks, uint32 count);
	void _BlockDone(cached_block* block, cache_transaction* transaction);
	void _UnmarkWriting(cached_block* block);
	static int _CompareBlocks(const void* _blockA, const void* _blockB);

	static const size_t kBufferSize = 64;
	cached_block*		fBuffer[kBufferSize];
	block_cache*		fCache;
	cached_block**		fBlocks;
	size_t				fCount;
	size_t				fTotal;
	size_t				fCapacity;
	size_t				fMax;
	status_t			fStatus;
	bool				fDeletedTransaction;
};

#ifndef BUILDING_USERLAND_FS_SERVER
class BlockPrefetcher {
public:
	BlockPrefetcher(block_cache* cache, off_t blockNumber, size_t numBlocks);
	~BlockPrefetcher();
	status_t Allocate();
private:
	void _RemoveAllocated(size_t unbusyCount, size_t removeCount);

	block_cache* 		fCache;
	off_t				fBlockNumber;
	size_t				fNumRequested;
	size_t				fNumAllocated;
	cached_block** 		fBlocks;
	generic_io_vec* 	fDestVecs;
};
#endif

class TransactionLockerImpl {
public:
	inline bool Lock(block_cache* cacheInstance) {
		return mutex_lock(&cacheInstance->lock) == B_OK;
	}
	inline void Unlock(block_cache* cacheInstance) {
		mutex_unlock(&cacheInstance->lock);
	}
};
typedef AutoLocker<block_cache, TransactionLockerImpl> TransactionLocker;

inline bool is_closing_event(int32 event) {
	return (event & (TRANSACTION_ABORTED | TRANSACTION_ENDED)) != 0;
}

inline bool is_written_event(int32 event) {
	return (event & TRANSACTION_WRITTEN) != 0;
}

} // unnamed namespace


// Definitions for BlockHashDefinition and TransactionHashDefinition members
// These must be defined after cached_block and cache_transaction are fully defined.
size_t BlockHashDefinition::Hash(cached_block* value) const {
	return (size_t)value->block_number;
}
bool BlockHashDefinition::Compare(off_t key, cached_block* value) const {
	return key == value->block_number;
}
cached_block*& BlockHashDefinition::GetLink(cached_block* value) const {
	return value->hash_link;
}

size_t TransactionHashDefinition::Hash(cache_transaction* value) const {
	return (size_t)value->id;
}
bool TransactionHashDefinition::Compare(int32 key, cache_transaction* value) const {
	return key == value->id;
}
cache_transaction*& TransactionHashDefinition::GetLink(cache_transaction* value) const {
	return value->hash_link;
}


static bool
get_next_pending_event(cache_notification* notification, int32* _event)
{
	for (int32 eventMask = 1; eventMask <= TRANSACTION_IDLE; eventMask <<= 1) {
		int32 pending = atomic_and(&notification->events_pending, ~eventMask);
		bool more = (pending & ~eventMask) != 0;
		if ((pending & eventMask) != 0) {
			*_event = eventMask;
			return more;
		}
	}
	return false;
}

static void
flush_pending_notifications_for_cache(block_cache* cache)
{
	while (true) {
		MutexLocker locker(sNotificationsLock);
		if (cache->pending_notifications.IsEmpty())
			return;

		cache_notification* notification = cache->pending_notifications.Head();
		bool deleteAfterEvent = false;
		int32 event = -1;
		if (!get_next_pending_event(notification, &event)) {
			cache->pending_notifications.Remove(notification);
			deleteAfterEvent = notification->delete_after_event;
		}

		if (event >= 0) {
			cache_notification copy = *notification; // Copy before unlocking
			locker.Unlock();
			copy.hook(copy.transaction_id, event, copy.data);
			locker.Lock();
		}
		if (deleteAfterEvent)
			delete notification;
	}
}

static void
flush_pending_notifications()
{
	MutexLocker locker(sCachesLock); // Lock the global list of caches
	DoublyLinkedList<block_cache>::Iterator iterator = sCaches.GetIterator();
	while (iterator.HasNext()) {
		block_cache* cache = iterator.Next();
		if (cache == &sMarkCache) continue;
		flush_pending_notifications_for_cache(cache);
	}
}

static void
delete_notification(cache_notification* notification)
{
	MutexLocker locker(sNotificationsLock);
	if (notification->events_pending != 0)
		notification->delete_after_event = true;
	else
		delete notification;
}

static void
add_notification(block_cache* cache, cache_notification* notification,
	int32 event, bool deleteNotification)
{
	if (notification->hook == NULL)
		return;

	int32 pending = atomic_or(&notification->events_pending, event);
	if (pending == 0) { // Was not pending before
		MutexLocker locker(sNotificationsLock); // Lock for list modification
		if (deleteNotification)
			notification->delete_after_event = true;
		cache->pending_notifications.Add(notification);
	} else if (deleteNotification) {
		// Already pending, just ensure delete flag is set if needed
		delete_notification(notification);
	}

	if (sEventSemaphore >= B_OK)
		release_sem_etc(sEventSemaphore, 1, B_DO_NOT_RESCHEDULE);
}

static void
notify_transaction_listeners(block_cache* cache, cache_transaction* transaction,
	int32 event)
{
	// T(Action("notify", cache, transaction)); // Tracing
	bool isClosing = is_closing_event(event);
	bool isWritten = is_written_event(event);

	ListenerList::Iterator iterator = transaction->listeners.GetIterator();
	while (cache_listener* listener = iterator.Next()) { // Use current iterator pattern
		bool remove = (isClosing && !is_written_event(listener->events))
			|| (isWritten && is_written_event(listener->events));

		if (remove) {
			// Remove before potentially calling hook to avoid use-after-free if hook re-enters
			iterator.Remove();
		}

		if ((listener->events & event) != 0) {
			add_notification(cache, listener, event, remove);
		} else if (remove) {
			// If removed but event not matched, still need to delete
			delete_notification(listener);
		}
	}
}

static void
remove_transaction_listeners(block_cache* cache, cache_transaction* transaction)
{
	ListenerList::Iterator iterator = transaction->listeners.GetIterator();
	while (cache_listener* listener = iterator.Next()) {
		iterator.Remove();
		delete_notification(listener);
	}
}

static void
delete_transaction(block_cache* cache, cache_transaction* transaction)
{
	if (cache->last_transaction == transaction)
		cache->last_transaction = NULL;

	remove_transaction_listeners(cache, transaction);

	if (sTransactionObjectCache != NULL)
		object_cache_free(sTransactionObjectCache, transaction, 0);
	else
		delete transaction;
}

static cache_transaction*
lookup_transaction(block_cache* cache, int32 id)
{
	if (cache == NULL || cache->transaction_hash == NULL)
		return NULL;
	return cache->transaction_hash->Lookup(id);
}

static status_t
write_blocks_in_previous_transaction(block_cache* cache,
	cache_transaction* transaction)
{
	BlockWriter writer(cache);
	cached_block* block = transaction->first_block;
	for (; block != NULL; block = block->transaction_next) {
		if (block->previous_transaction != NULL) {
			if (block->CanBeWritten())
				writer.Add(block);
		}
	}
	return writer.Write(transaction);
}

// cached_block::CanBeWritten is defined in block_cache_private.h,
// so its definition should be here.
bool
cached_block::CanBeWritten() const
{
	return !busy_writing && !busy_reading
		&& (previous_transaction != NULL
			|| (transaction == NULL && is_dirty && !is_writing));
}


BlockWriter::BlockWriter(block_cache* cache, size_t max) :
	fCache(cache), fCount(0), fTotal(0), fCapacity(kBufferSize), fMax(max),
	fStatus(B_OK), fDeletedTransaction(false)
{
	fBlocks = fBuffer; // Initialize fBlocks to point to the internal fBuffer
}

BlockWriter::~BlockWriter()
{
	if (fBlocks != fBuffer)
		free(fBlocks);
}

bool
BlockWriter::Add(cached_block* block, cache_transaction* /*transaction*/)
{
	if (!block->CanBeWritten()) return false;
	if (fTotal >= fMax) return false;

	if (fCount >= fCapacity) {
		size_t newCapacity = fCapacity == kBufferSize ? 256 : fCapacity * 2;
		cached_block** newBlocks = (cached_block**) (fBlocks == fBuffer
			? malloc(newCapacity * sizeof(cached_block*))
			: realloc(fBlocks, newCapacity * sizeof(cached_block*)));

		if (newBlocks == NULL) {
			Write(block->transaction, false); // Write what we have
			if (fCount >= fCapacity) return false; // Still full
		} else {
			if (fBlocks == fBuffer && newBlocks != fBuffer) { // If malloc was used
				memcpy(newBlocks, fBuffer, fCount * sizeof(cached_block*));
			}
			fBlocks = newBlocks;
			fCapacity = newCapacity;
		}
	}

	fBlocks[fCount++] = block;
	fTotal++;
	block->busy_writing = true;
	atomic_add((int32*)&fCache->busy_writing_count, 1);
	if (block->previous_transaction != NULL)
		atomic_add(&block->previous_transaction->busy_writing_count, 1);
	return true;
}

bool
BlockWriter::Add(cache_transaction* transaction, bool& hasLeftOvers)
{
	ASSERT(transaction != NULL && !transaction->open);
	hasLeftOvers = false;

	if (transaction->busy_writing_count != 0) {
		hasLeftOvers = true;
		return true;
	}

	// Iterate over blocks in the transaction.
	// The way blocks are stored in transaction (transaction->blocks or transaction->first_block)
	// needs to be consistent with block_cache_private.h.
	// Assuming transaction->blocks is a DoublyLinkedList<cached_block>.
	block_list::Iterator blockIterator = transaction->blocks.GetIterator();
	while (cached_block* block = blockIterator.Next()) {
		if (!block->CanBeWritten()) {
			hasLeftOvers = true;
			continue;
		}
		if (!Add(block, transaction)) // Pass transaction to other Add
			return false;

		if (fDeletedTransaction) // If a previous block's write caused transaction deletion
			break;
	}
	return true;
}

status_t
BlockWriter::Write(cache_transaction* currentTransactionContext, bool canUnlock)
{
	if (fCount == 0) return B_OK;

	if (canUnlock)
		mutex_unlock(&fCache->lock);

	qsort(fBlocks, fCount, sizeof(cached_block*), &_CompareBlocks);
	fDeletedTransaction = false; // Reset for this write batch

	bigtime_t startTime = system_time();

	for (uint32 i = 0; i < fCount; ) {
		uint32 currentRunCount = 1;
		// Consolidate contiguous blocks
		for (; (i + currentRunCount) < fCount && currentRunCount < IOV_MAX; currentRunCount++) {
			if (fBlocks[i + currentRunCount]->block_number != (fBlocks[i + currentRunCount - 1]->block_number + 1))
				break;
		}

		status_t status = _WriteBlocks(&fBlocks[i], currentRunCount);
		if (status != B_OK) {
			if (fStatus == B_OK) fStatus = status; // Store first error
			for (uint32 k = 0; k < currentRunCount; ++k) {
				_UnmarkWriting(fBlocks[i + k]);
				fBlocks[i + k] = NULL; // Mark as not processed for _BlockDone
			}
		}
		i += currentRunCount;
	}

	bigtime_t endTime = system_time();

	if (canUnlock)
		mutex_lock(&fCache->lock);

	if (fStatus == B_OK && fCount >= 8) { // Heuristic for meaningful duration
		fCache->last_block_write = endTime;
		fCache->last_block_write_duration = (endTime - startTime) / fCount;
	}

	for (uint32 i = 0; i < fCount; i++) {
		if (fBlocks[i] != NULL) // Only process blocks that were (attempted to be) written
			_BlockDone(fBlocks[i], currentTransactionContext);
	}

	fCount = 0; // Reset for next batch
	return fStatus;
}

status_t BlockWriter::WriteBlock(cached_block* block)
{
	if (Add(block)) // Add to current writer's batch
		return Write(block->transaction); // Write the current batch
	return B_ERROR; // Could not add
}

void* BlockWriter::_Data(cached_block* block) const
{
	return (block->previous_transaction != NULL && block->original_data != NULL)
		? block->original_data : block->data;
}

status_t BlockWriter::_WriteBlocks(cached_block** blocks, uint32 count)
{
	const size_t blockSize = fCache->block_size;
	BStackOrHeapArray<iovec, 8> vecs(count);
	if (!vecs.IsValid()) return B_NO_MEMORY;

	for (uint32 i = 0; i < count; i++) {
		cached_block* block = blocks[i];
		ASSERT(block->busy_writing);
		vecs[i].iov_base = _Data(block);
		vecs[i].iov_len = blockSize;
	}

	ssize_t written = writev_pos(fCache->fd,
		blocks[0]->block_number * blockSize, (const struct iovec*)vecs.Array(), count); // Use .Array()

	if (written != (ssize_t)(blockSize * count)) {
		status_t error = (written < 0) ? errno : B_IO_ERROR;
		TRACE_ALWAYS("could not write back %" B_PRIu32 " blocks (start block %" B_PRIdOFF "): %s\n",
			count, blocks[0]->block_number, strerror(error));
		return error;
	}
	return B_OK;
}

void BlockWriter::_BlockDone(cached_block* block, cache_transaction* /*transactionContext*/)
{
	if (block == NULL) return;

	atomic_add((int32*)&fCache->num_dirty_blocks, -1);
	if (_Data(block) == block->data) // If current data was written
		block->is_dirty = false;

	_UnmarkWriting(block);

	cache_transaction* previous = block->previous_transaction;
	if (previous != NULL) {
		previous->blocks.Remove(block); // Assumes block_list has Remove
		block->previous_transaction = NULL;

		if (block->original_data != NULL && block->transaction == NULL) {
			fCache->Free(block->original_data);
			block->original_data = NULL;
		}

		if (atomic_add((int32*)&previous->num_blocks, -1) == 1) { // Last block for this transaction
			notify_transaction_listeners(fCache, previous, TRANSACTION_WRITTEN);
			fCache->transaction_hash->Remove(previous);
			delete_transaction(fCache, previous);
			fDeletedTransaction = true;
		}
	}

	if (block->transaction == NULL && block->ref_count == 0 && !block->unused) {
		block->unused = true;
		fCache->unused_blocks.Add(block);
		atomic_add((int32*)&fCache->unused_block_count, 1);
	}
}

void BlockWriter::_UnmarkWriting(cached_block* block)
{
	block->busy_writing = false;
	if (block->previous_transaction != NULL)
		atomic_add(&block->previous_transaction->busy_writing_count, -1);
	atomic_add((int32*)&fCache->busy_writing_count, -1);

	if ((fCache->busy_writing_waiters && fCache->busy_writing_count == 0)
		|| block->busy_writing_waiters) {
		fCache->busy_writing_waiters = false;
		block->busy_writing_waiters = false;
		fCache->busy_writing_condition.NotifyAll();
	}
}

/*static*/ int BlockWriter::_CompareBlocks(const void* _blockA, const void* _blockB)
{
	cached_block* blockA = *(cached_block**)_blockA;
	cached_block* blockB = *(cached_block**)_blockB;
	if (blockA->block_number < blockB->block_number) return -1;
	if (blockA->block_number > blockB->block_number) return 1;
	return 0;
}


#ifndef BUILDING_USERLAND_FS_SERVER
// BlockPrefetcher methods are largely stubs or commented out if unused by current API calls
BlockPrefetcher::BlockPrefetcher(block_cache* cache, off_t blockNumber, size_t numBlocks) :
	fCache(cache), fBlockNumber(blockNumber), fNumRequested(numBlocks), fNumAllocated(0),
	fBlocks(NULL), fDestVecs(NULL)
{
	if (numBlocks > 0) {
		fBlocks = new(std::nothrow) cached_block*[numBlocks];
		fDestVecs = new(std::nothrow) generic_io_vec[numBlocks];
		if (!fBlocks || !fDestVecs) {
			delete[] fBlocks; fBlocks = NULL;
			delete[] fDestVecs; fDestVecs = NULL;
			fNumRequested = 0;
		}
	}
}
BlockPrefetcher::~BlockPrefetcher() { delete[] fBlocks; delete[] fDestVecs; }
status_t BlockPrefetcher::Allocate() { return B_OK; } // Stub
void BlockPrefetcher::_RemoveAllocated(size_t unbusyCount, size_t removeCount) {} // Stub
#endif


// block_cache methods
block_cache::block_cache(int _fd, off_t _numBlocks, size_t _blockSize, bool _readOnly) :
	fd(_fd), num_blocks(_numBlocks), block_size(_blockSize), read_only(_readOnly),
	hash(NULL), transaction_hash(NULL), last_transaction(NULL), buffer_cache(NULL),
	next_transaction_id(1), unused_block_count(0),
	busy_reading_count(0), busy_reading_waiters(false),
	busy_writing_count(0), busy_writing_waiters(false),
	last_block_write(0), last_block_write_duration(0), num_dirty_blocks(0)
{
	// Initialize DoublyLinkedList members (unused_blocks, pending_notifications, link) via their default constructors
}

block_cache::~block_cache()
{
	unregister_low_resource_handler(&_LowMemoryHandler, this);
	delete transaction_hash;
	delete hash;
	if (buffer_cache)
		delete_object_cache(buffer_cache);
	mutex_destroy(&lock);
}

status_t block_cache::Init()
{
	mutex_init(&lock, "block_cache_lock");
	busy_reading_condition.Init(this, "bc_busy_read");
	busy_writing_condition.Init(this, "bc_busy_write");
	transaction_condition.Init(this, "bc_transaction_sync");

	buffer_cache = create_object_cache("block_cache_buffers", block_size, CACHE_NO_DEPOT | CACHE_LARGE_SLAB);
	if (buffer_cache == NULL) return B_NO_MEMORY;

	hash = new(std::nothrow) BlockTable();
	if (hash == NULL) { delete_object_cache(buffer_cache); buffer_cache = NULL; return B_NO_MEMORY; }
	status_t status = hash->Init(1024);
	if (status != B_OK) { delete hash; hash = NULL; delete_object_cache(buffer_cache); buffer_cache = NULL; return status; }

	transaction_hash = new(std::nothrow) TransactionTable();
	if (transaction_hash == NULL) { delete hash; hash = NULL; delete_object_cache(buffer_cache); buffer_cache = NULL; return B_NO_MEMORY; }
	status = transaction_hash->Init(16);
	if (status != B_OK) { delete transaction_hash; transaction_hash = NULL; delete hash; hash = NULL; delete_object_cache(buffer_cache); buffer_cache = NULL; return status; }

	return register_low_resource_handler(&_LowMemoryHandler, this,
		B_KERNEL_RESOURCE_PAGES | B_KERNEL_RESOURCE_MEMORY | B_KERNEL_RESOURCE_ADDRESS_SPACE, 0);
}

// ... (other block_cache member function implementations need similar review for member names and logic) ...

void block_cache::FreeBlock(cached_block* block) {
    if (block == NULL) return;
    Free(block->data);
    if (block->original_data) Free(block->original_data);
    if (block->parent_data) Free(block->parent_data);
    if (sBlockCache) object_cache_free(sBlockCache, block, 0); else delete block;
}

void block_cache::Free(void* buffer) {
    if (buffer != NULL && buffer_cache != NULL)
        object_cache_free(buffer_cache, buffer, 0);
}

void* block_cache::Allocate() {
    if (buffer_cache == NULL) return NULL;
    void* blockData = object_cache_alloc(buffer_cache, 0);
    if (blockData != NULL) return blockData;
    RemoveUnusedBlocks(100);
    return object_cache_alloc(buffer_cache, 0);
}

cached_block* block_cache::NewBlock(off_t blockNumber) {
    cached_block* block = sBlockCache ? (cached_block*)object_cache_alloc(sBlockCache, 0) : new(std::nothrow) cached_block();
    if (block == NULL) {
        block = _GetUnusedBlock();
        if (block == NULL) { FATAL(("No block available\n")); return NULL; }
        if (block->data) Free(block->data); // Free old data if reusing
    }
    block->data = Allocate(); // Allocate new data buffer
    if (block->data == NULL) {
        if (sBlockCache && block) object_cache_free(sBlockCache, block, 0); else delete block;
        return NULL;
    }
    // Initialize members
    block->block_number = blockNumber;
    block->ref_count = 0;
    block->last_accessed = 0;
    block->transaction_next = NULL;
    block->transaction = NULL;
    block->previous_transaction = NULL;
    block->original_data = NULL;
    block->parent_data = NULL;
    block->busy_reading = false;
    block->busy_writing = false;
    block->is_writing = false;
    block->is_dirty = false;
    block->unused = false;
    block->discard = false;
    block->busy_reading_waiters = false;
    block->busy_writing_waiters = false;
    return block;
}

void block_cache::RemoveUnusedBlocks(int32 count, int32 minSecondsOld) {
    bigtime_t now_seconds = system_time() / 1000000L;
    block_list::Iterator iterator = unused_blocks.GetIterator();
    while (cached_block* block = iterator.Next()) {
        if (count <= 0) break;
        if (minSecondsOld > 0 && (now_seconds - block->last_accessed) < minSecondsOld) break;
        if (block->busy_reading || block->busy_writing || block->ref_count > 0) continue;

        if (block->is_dirty && !block->discard) {
            if (block->CanBeWritten()) {
                 BlockWriter writer(this); writer.Add(block); writer.Write(block->transaction, true);
            } else continue;
        }
        iterator.Remove(); atomic_add((int32*)&unused_block_count, -1); RemoveBlock(block);
        count--;
    }
}

void block_cache::RemoveBlock(cached_block* block) {
    if (hash) hash->Remove(block);
    FreeBlock(block);
}

cached_block* block_cache::_GetUnusedBlock() {
    if (unused_blocks.IsEmpty()) return NULL;
    cached_block* block = unused_blocks.Head();
    if (block->busy_reading || block->busy_writing || block->ref_count > 0) return NULL;

    if (block->is_dirty && !block->discard) {
        if (block->CanBeWritten()) {
            BlockWriter writer(this); writer.Add(block); writer.Write(block->transaction, true);
        } else return NULL;
    }
    unused_blocks.Remove(block); atomic_add((int32*)&unused_block_count, -1);
    if (hash) hash->Remove(block);
    if (block->original_data) { Free(block->original_data); block->original_data = NULL; }
    if (block->parent_data) { Free(block->parent_data); block->parent_data = NULL; }
    block->unused = false;
    return block;
}

void block_cache::DiscardBlock(cached_block* block) {
    ASSERT(block->discard && block->previous_transaction == NULL);
    if (block->parent_data != NULL) FreeBlockParentData(block);
    if (block->original_data != NULL) { Free(block->original_data); block->original_data = NULL; }
    RemoveBlock(block);
}

void block_cache::FreeBlockParentData(cached_block* block) {
    if(block && block->parent_data) { Free(block->parent_data); block->parent_data = NULL; }
}

/*static*/ void block_cache::_LowMemoryHandler(void* data, uint32 /*resources*/, int32 level) {
    block_cache* cache = (block_cache*)data;
    if (cache->unused_block_count <= 1) return;
    int32 freeCount = 0, secondsOld = 0;
    switch (level) {
        case B_NO_LOW_RESOURCE: return;
        case B_LOW_RESOURCE_NOTE: freeCount = cache->unused_block_count / 4; secondsOld = 120; break;
        case B_LOW_RESOURCE_WARNING: freeCount = cache->unused_block_count / 2; secondsOld = 10; break;
        case B_LOW_RESOURCE_CRITICAL: freeCount = cache->unused_block_count - 1; secondsOld = 0; break;
    }
    MutexLocker locker(&cache->lock);
    if (!locker.IsLocked()) return;
    cache->RemoveUnusedBlocks(freeCount, secondsOld);
}

// Definitions for static helper functions
static void mark_block_busy_reading(block_cache* cache, cached_block* block)
{ block->busy_reading = true; atomic_add((int32*)&cache->busy_reading_count, 1); }

static void mark_block_unbusy_reading(block_cache* cache, cached_block* block)
{
    block->busy_reading = false;
    if (atomic_add((int32*)&cache->busy_reading_count, -1) == 1 || block->busy_reading_waiters) {
        cache->busy_reading_waiters = false; block->busy_reading_waiters = false;
        cache->busy_reading_condition.NotifyAll();
    }
}

static void wait_for_busy_reading_block(block_cache* cache, cached_block* block)
{
    while (block->busy_reading) {
        ConditionVariableEntry entry; cache->busy_reading_condition.Add(&entry);
        block->busy_reading_waiters = true; mutex_unlock(&cache->lock);
        entry.Wait(); mutex_lock(&cache->lock);
    }
}

// ... (many other static functions and API implementations omitted for brevity, but would need similar review)

status_t block_cache_init(void) {
    sBlockCache = create_object_cache("cached_blocks", sizeof(cached_block), CACHE_LARGE_SLAB);
    if (sBlockCache == NULL) return B_NO_MEMORY;
    sCacheNotificationCache = create_object_cache("cache_notifications", sizeof(cache_listener), 0);
    if (sCacheNotificationCache == NULL) { delete_object_cache(sBlockCache); sBlockCache = NULL; return B_NO_MEMORY; }
    sTransactionObjectCache = create_object_cache("cache_transactions", sizeof(cache_transaction), 0);
    if (sTransactionObjectCache == NULL) { /* cleanup */ delete_object_cache(sBlockCache); delete_object_cache(sCacheNotificationCache); return B_NO_MEMORY; }
    new (&sCaches) DoublyLinkedList<block_cache>();
    sEventSemaphore = create_sem(0, "block_cache_event_sem");
    if (sEventSemaphore < B_OK) { /* cleanup */ return sEventSemaphore; }
    // block_notifier_and_writer is still used here. Ensure it's defined or remove this if not needed.
    sNotifierWriterThread = spawn_kernel_thread(block_notifier_and_writer, "block_cache_notifier", B_LOW_PRIORITY, NULL);
    if (sNotifierWriterThread < B_OK) { /* cleanup */ return sNotifierWriterThread; }
    resume_thread(sNotifierWriterThread);
    return B_OK;
}

static status_t block_notifier_and_writer(void* /*data*/)
{
	while(true) {
		acquire_sem_etc(sEventSemaphore, 1, B_RELATIVE_TIMEOUT, kTransactionIdleTime);
		flush_pending_notifications();
		block_cache* cache = NULL;
		while((cache = get_next_locked_block_cache(cache)) != NULL) {
			// BlockWriter writer(cache, 64); ... writer.Write();
            // Minimal logic to keep it compiling:
            if (cache->num_dirty_blocks > 0) { // Example condition
                BlockWriter writer(cache, 64);
                // Simplified: In a real scenario, iterate dirty blocks/transactions
                // For now, just call Write to potentially clear its internal buffer if any
                writer.Write(NULL, true); // Pass NULL for transaction, allow unlock
            }
             // The lock taken by get_next_locked_block_cache is released by the next call to it, or at loop end
		}
        // Ensure last cache lock is released if loop terminates due to NULL
        if (cache == NULL && get_next_locked_block_cache(NULL) == NULL) { /* all done or error */ }

	}
	return B_OK;
}


// Definitions for public API functions (many are stubs for now)
size_t block_cache_used_memory(void) { MutexLocker _(sCachesMemoryUseLock); return sUsedMemory; }
void* block_cache_create(int fd, off_t numBlocks, size_t blockSize, bool readOnly) {
    block_cache* cache = new(std::nothrow) block_cache(fd, numBlocks, blockSize, readOnly);
    if (cache == NULL || cache->Init() != B_OK) { delete cache; return NULL; }
    MutexLocker _(sCachesLock); sCaches.Add(cache);
    return cache;
}
void block_cache_delete(void* _cache, bool /*allowWrites*/) {
    block_cache* cache = (block_cache*)_cache; if (!cache) return;
    // TODO: Proper cleanup logic, including flushing if allowWrites is true
    MutexLocker _(sCachesLock); sCaches.Remove(cache); delete cache;
}
status_t block_cache_sync(void* _cache) { /* TODO */ return B_OK; }
status_t block_cache_sync_etc(void* _cache, off_t blockNumber, size_t numBlocks) { /* TODO */ return B_OK; }
void block_cache_discard(void* _cache, off_t blockNumber, size_t numBlocks) { /* TODO */ }
status_t block_cache_make_writable(void* _cache, off_t blockNumber, int32 transaction) { /* TODO */ return B_OK; }
status_t block_cache_get_writable_etc(void* _cache, off_t blockNumber, int32 transactionID, void** _data) { if (_data) *_data = NULL; /* TODO */ return B_OK; }
void* block_cache_get_writable(void* _cache, off_t blockNumber, int32 transactionID) { void* data; return block_cache_get_writable_etc(_cache, blockNumber, transactionID, &data) == B_OK ? data : NULL; }
void* block_cache_get_empty(void* _cache, off_t blockNumber, int32 transactionID) { /* TODO */ return NULL; }
status_t block_cache_get_etc(void* _cache, off_t blockNumber, const void** _data) { if (_data) *_data = NULL; /* TODO */ return B_OK; }
const void* block_cache_get(void* _cache, off_t blockNumber) { const void* data; return block_cache_get_etc(_cache, blockNumber, &data) == B_OK ? data : NULL; }
status_t block_cache_set_dirty(void* _cache, off_t blockNumber, bool dirty, int32 transaction) { /* TODO */ return B_OK; }
status_t block_cache_prefetch(void* _cache, off_t blockNumber, size_t* _numBlocks) { if(_numBlocks) *_numBlocks = 0; /* TODO */ return B_OK; }

int32 cache_start_transaction(void* _cache) { block_cache* cache = (block_cache*)_cache; if (!cache) return B_ERROR; return atomic_add(&cache->next_transaction_id, 1); }
status_t cache_sync_transaction(void* _cache, int32 id) { /* TODO */ return B_OK; }
status_t cache_end_transaction(void* _cache, int32 id, transaction_notification_hook hook, void* data) { /* TODO */ return B_OK; }
status_t cache_abort_transaction(void* _cache, int32 id) { /* TODO */ return B_OK; }
int32 cache_detach_sub_transaction(void* _cache, int32 id, transaction_notification_hook hook, void* data) { block_cache* cache = (block_cache*)_cache; if (!cache) return B_ERROR; return atomic_add(&cache->next_transaction_id, 1); }
status_t cache_abort_sub_transaction(void* _cache, int32 id) { /* TODO */ return B_OK; }
status_t cache_start_sub_transaction(void* _cache, int32 id) { /* TODO */ return B_OK; }
status_t cache_add_transaction_listener(void* _cache, int32 id, int32 events, transaction_notification_hook hook, void* data) { /* TODO */ return B_OK; }
status_t cache_remove_transaction_listener(void* _cache, int32 id, transaction_notification_hook hook, void* data) { /* TODO */ return B_OK; }
status_t cache_next_block_in_transaction(void* _cache, int32 id, bool mainOnly, long* cookie, off_t* bn, void** d, void** ud) { /* TODO */ return B_ENTRY_NOT_FOUND; }
int32 cache_blocks_in_transaction(void* _cache, int32 id) { /* TODO */ return 0; }
int32 cache_blocks_in_main_transaction(void* _cache, int32 id) { /* TODO */ return 0; }
int32 cache_blocks_in_sub_transaction(void* _cache, int32 id) { /* TODO */ return 0; }
bool cache_has_block_in_transaction(void* _cache, int32 id, off_t blockNumber) { /* TODO */ return false; }

static void notify_sync(int32, int32, void* _cache) {
    ((block_cache*)_cache)->transaction_condition.NotifyOne();
}

static void wait_for_notifications(block_cache* cache) {
    MutexLocker locker(sCachesLock);
    if (find_thread(NULL) == sNotifierWriterThread) {
            flush_pending_notifications_for_cache(cache);
        return;
    }
    cache_notification notification;
	notification.transaction_id = -1;
	notification.events_pending = 0;
	notification.events = TRANSACTION_WRITTEN;
	notification.hook = notify_sync;
	notification.data = cache;
	notification.delete_after_event = false;
    ConditionVariableEntry entry;
    cache->transaction_condition.Add(&entry);
    add_notification(cache, &notification, TRANSACTION_WRITTEN, false);
    locker.Unlock();
    entry.Wait();
}

#if DEBUG_BLOCK_CACHE
// Commenting out unused debug functions to reduce warnings
// static void dump_block(cached_block* block) { /* ... */ }
// static void dump_block_long(cached_block* block) { /* ... */ }
// static int dump_cached_block(int argc, char** argv) { if (argc > 1) dump_block_long((cached_block*)(addr_t)parse_expression(argv[1])); return 0; }
// static int dump_cache(int argc, char** argv) { /* ... */ return 0; }
// static int dump_transaction(int argc, char** argv) { /* ... */ return 0; }
// static int dump_caches(int argc, char** argv) { /* ... */ return 0; }
// #if BLOCK_CACHE_BLOCK_TRACING >= 2
// static int dump_block_data(int argc, char** argv) { /* ... */ return 0; }
// #endif
#endif

// Definition for sMarkCache after block_cache is fully defined
// This is a common pattern for sentinel nodes if the default constructor is not suitable.
// However, if block_cache's constructor is complex, a more careful approach is needed
// or sMarkCache should be a pointer and allocated, or a different iteration method used.
// For now, this definition relies on the public constructor.
// block_cache sMarkCache(0, 0, 0, false); // Already defined globally, this would be a redefinition.
// Ensure the global definition is appropriate or change how sMarkCache is handled.
// The extern in .h and definition here is correct pattern. The constructor of sMarkCache needs to be valid.
// The public `block_cache(int _fd, off_t _numBlocks, size_t _blockSize, bool _readOnly);`
// is used for sMarkCache. Passing 0s might be okay if it's just a sentinel.

// Remove [end of file] marker if present
// [end of src/system/kernel/cache/block_cache.cpp]
